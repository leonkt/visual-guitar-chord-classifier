{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7TP9MRLEe-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edYN5FFmQmDQ",
        "colab_type": "code",
        "outputId": "83c417e8-7da9-4c0e-d501-4852865bdfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECHScoN_JFhy",
        "colab_type": "code",
        "outputId": "bd796b3e-6825-46d0-815a-8f4fd5026abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                    transforms.Resize(224),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "root = \"/content/drive/My Drive/Guitar Dataset/Workflow/Official Dataset\"\n",
        "full_set = datasets.ImageFolder(root=root, transform=transform)\n",
        "train_size = int(0.8 * len(full_set))\n",
        "test_size = len(full_set) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(full_set, [train_size, test_size])\n",
        "\n",
        "dataset_sizes = {'train': len(train_set),\n",
        "                 'test': len(test_set)\n",
        "                }\n",
        "dataloaders = {'train': torch.utils.data.DataLoader(train_set, shuffle=True, num_workers=0),\n",
        "               'test': torch.utils.data.DataLoader(test_set, shuffle=False, num_workers=0)\n",
        "              }\n",
        "\n",
        "print (full_set.classes)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C', 'D', 'Em', 'F', 'G']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8JjEz2Xrqa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe95egSEp9MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjv4OrXEtAmF",
        "colab_type": "code",
        "outputId": "6a682581-b14a-4132-d4e0-7394a6122caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 2.4625 Acc: 0.2128\n",
            "test Loss: 3.5586 Acc: 0.3108\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.7767 Acc: 0.2534\n",
            "test Loss: 3.1510 Acc: 0.1892\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 2.7233 Acc: 0.2128\n",
            "test Loss: 3.6380 Acc: 0.1486\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 2.8630 Acc: 0.2230\n",
            "test Loss: 3.2893 Acc: 0.1351\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 2.7989 Acc: 0.2196\n",
            "test Loss: 4.4261 Acc: 0.1486\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 2.9923 Acc: 0.2061\n",
            "test Loss: 4.3817 Acc: 0.1892\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 2.6679 Acc: 0.2061\n",
            "test Loss: 3.8894 Acc: 0.2027\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.7038 Acc: 0.3007\n",
            "test Loss: 1.6971 Acc: 0.2973\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.5913 Acc: 0.3209\n",
            "test Loss: 1.7751 Acc: 0.2162\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.5880 Acc: 0.2635\n",
            "test Loss: 1.8697 Acc: 0.1757\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.5924 Acc: 0.3142\n",
            "test Loss: 1.7153 Acc: 0.2568\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.5867 Acc: 0.2939\n",
            "test Loss: 1.6877 Acc: 0.4054\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.5638 Acc: 0.3412\n",
            "test Loss: 1.6176 Acc: 0.2568\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.5473 Acc: 0.3074\n",
            "test Loss: 1.6952 Acc: 0.2568\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.5243 Acc: 0.3446\n",
            "test Loss: 1.6652 Acc: 0.2432\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.5031 Acc: 0.3311\n",
            "test Loss: 1.6615 Acc: 0.2973\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.5035 Acc: 0.3953\n",
            "test Loss: 1.6154 Acc: 0.3243\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.5070 Acc: 0.3176\n",
            "test Loss: 1.6170 Acc: 0.2838\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.5048 Acc: 0.3311\n",
            "test Loss: 1.6914 Acc: 0.2838\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.5051 Acc: 0.3446\n",
            "test Loss: 1.6218 Acc: 0.2703\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.5072 Acc: 0.3716\n",
            "test Loss: 1.6137 Acc: 0.2838\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.4950 Acc: 0.3716\n",
            "test Loss: 1.6466 Acc: 0.3108\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.4922 Acc: 0.3851\n",
            "test Loss: 1.6121 Acc: 0.2838\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.4929 Acc: 0.3581\n",
            "test Loss: 1.6509 Acc: 0.2568\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.4942 Acc: 0.3514\n",
            "test Loss: 1.6560 Acc: 0.3108\n",
            "\n",
            "Training complete in 22m 44s\n",
            "Best val Acc: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr3S6TBHuJS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCXDrzxP0BBf",
        "colab_type": "code",
        "outputId": "ffb2f5e8-4d9b-439b-983c-12c3dfb0ee48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-b590b3d1873b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-2409e05e05bb>\u001b[0m in \u001b[0;36mvisualize_model\u001b[0;34m(model, num_images)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_so_far\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKYAAABOCAYAAACqn22YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAA6klEQVR4nO3SMQEAIAzAMMC/52GAnx6Jgh7dM7Og\n5vwOgBdjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJ\nMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRM\nkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZ\nkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJuiISA5nXU27HAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_8FrNmz0DlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}